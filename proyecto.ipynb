{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "test_path = 'test_data/'\n",
    "outpath = 'output/'\n",
    "\n",
    "# 'id':'name'\n",
    "photo_dic = {}\n",
    "\n",
    "# Array of known face encodings \n",
    "known_face_encodings = []\n",
    "known_face_ids=[]\n",
    "\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'79578': 'Alarcón Allan', '2808': 'Julio Alvia', '78451': 'Andrade Bravo'}\n",
      "Julio Alvia\n"
     ]
    }
   ],
   "source": [
    "for dirname, dirnames, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        photo = os.path.join(dirname, filename)\n",
    "#         print(photo)\n",
    "        photo_data = photo.split(\"/\")[2].split(\".\")[0].split(\"_\")\n",
    "        photo_id = photo_data[1]\n",
    "        photo_name = \"{} {}\".format(photo_data[3], photo_data[4])\n",
    "        if photo_id not in photo_dic:\n",
    "            photo_dic[photo_id] = photo_name\n",
    "\n",
    "print(photo_dic)\n",
    "print(photo_dic[photo_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "# detector= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_encoding - the model learns how to recognize it\n",
    "# face_id - to use it on the dictionary\n",
    "# photo_type - is grupal or not.\n",
    "\n",
    "def getImagesAndLabels(data_path): \n",
    "    total_test = 0\n",
    "    total_data = 0\n",
    "    encoded_at_first_try = 0\n",
    "    encoded_with_locations = 0\n",
    "    no_encoded = 0\n",
    "    \n",
    "    for dirname, dirnames, filenames in os.walk(data_path):\n",
    "        for filename in filenames:\n",
    "            photo_path = os.path.join(dirname, filename)\n",
    "            #print(photo_path)\n",
    "            face_id =int(photo_path.split(\"/\")[2].split(\".\")[0].split(\"_\")[1])\n",
    "            photo_type = photo_path.split(\"/\")[2].split(\".\")[0].split(\"_\")[-1]\n",
    "            \n",
    "            if photo_type.lower() == \"grupal\":\n",
    "                test_data.append(photo_path)\n",
    "                total_test += 1\n",
    "            else:\n",
    "                total_data += 1\n",
    "                image_loaded = face_recognition.load_image_file(photo_path)\n",
    "                face_encoding = face_recognition.face_encodings(image_loaded)\n",
    "\n",
    "                if face_encoding == []:\n",
    "                    img = cv2.imread(photo_path,0)\n",
    "                    height, width = img.shape[:2]\n",
    "                    known_face_locations=[(0, width, height, 0)]\n",
    "                    face_encoding = face_recognition.face_encodings(image_loaded,known_face_locations)\n",
    "\n",
    "                    if face_encoding == []:\n",
    "                        no_encoded += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        encoded_with_locations += 1\n",
    "                else:\n",
    "                    encoded_at_first_try += 1\n",
    "\n",
    "                face_encoding = face_encoding[0]\n",
    "                \n",
    "                known_face_encodings.append(face_encoding)\n",
    "                known_face_ids.append(face_id)\n",
    "            \n",
    "            print(str(no_encoded) +\" de \"+str(total_data)+\" sin encoding\")\n",
    "            print(str(total_test) + \" para test\")\n",
    "    return known_face_encodings, known_face_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesToTest(test_path):\n",
    "\n",
    "    for dirname, dirnames, filenames in os.walk(test_path):\n",
    "        for filename in filenames:\n",
    "            photo_path = os.path.join(dirname, filename)\n",
    "            print(photo_path)\n",
    "            test_data.append(photo_path)\n",
    "                       \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleFont(photo):\n",
    "    img = cv2.imread(photo,0)\n",
    "    height, width = img.shape[:2]\n",
    "    min_value = min(height,width)\n",
    "    max_value = max(height,width)\n",
    "    if min_value < 900:\n",
    "        return min_value/900\n",
    "    elif max_value > 1300:\n",
    "        return max_value/1300\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 de 0 sin encoding\n",
      "1 para test\n",
      "0 de 1 sin encoding\n",
      "1 para test\n",
      "0 de 2 sin encoding\n",
      "1 para test\n",
      "0 de 3 sin encoding\n",
      "1 para test\n",
      "0 de 4 sin encoding\n",
      "1 para test\n",
      "0 de 5 sin encoding\n",
      "1 para test\n",
      "0 de 6 sin encoding\n",
      "1 para test\n",
      "0 de 6 sin encoding\n",
      "2 para test\n",
      "0 de 7 sin encoding\n",
      "2 para test\n",
      "0 de 8 sin encoding\n",
      "2 para test\n",
      "0 de 9 sin encoding\n",
      "2 para test\n",
      "0 de 10 sin encoding\n",
      "2 para test\n",
      "0 de 11 sin encoding\n",
      "2 para test\n",
      "0 de 11 sin encoding\n",
      "3 para test\n",
      "0 de 12 sin encoding\n",
      "3 para test\n",
      "0 de 13 sin encoding\n",
      "3 para test\n",
      "0 de 14 sin encoding\n",
      "3 para test\n",
      "0 de 15 sin encoding\n",
      "3 para test\n",
      "0 de 16 sin encoding\n",
      "3 para test\n",
      "0 de 17 sin encoding\n",
      "3 para test\n",
      "0 de 18 sin encoding\n",
      "3 para test\n"
     ]
    }
   ],
   "source": [
    "known_face_encodings, known_face_ids = getImagesAndLabels(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data/alarconyepezallansamuel_79578_1302992_Alarcón_Allan_grupal.jpg\n",
      "test_data/alviaapraezjulioernesto_2808_1303099_Julio_Alvia_grupal.jpg\n",
      "test_data/andradebravoboscoarmando_78451_1338359_Andrade_Bravo_grupal.jpg\n",
      "3\n",
      "[79578]\n",
      "3\n",
      "[2808]\n",
      "2\n",
      "[78451]\n",
      "['test_data/alarconyepezallansamuel_79578_1302992_Alarcón_Allan_grupal.jpg', 'test_data/alviaapraezjulioernesto_2808_1303099_Julio_Alvia_grupal.jpg', 'test_data/andradebravoboscoarmando_78451_1338359_Andrade_Bravo_grupal.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "test_data = getImagesToTest(test_path)\n",
    "for unknown_image in test_data:\n",
    "    #face_locations = face_recognition.face_locations(rgb_image)\n",
    "    image_loaded = face_recognition.load_image_file(unknown_image)\n",
    "    rgb_image = image_loaded[...,::-1]\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "    #face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "    #print(face_encodings)\n",
    "#     Id=\"\"\n",
    "    scaledFont = 1.0 * scaleFont(unknown_image)\n",
    "    face_ids=[]\n",
    "    print(len(face_encodings))\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        Id = -1\n",
    "    \n",
    "    #print(unknown_image)\n",
    "    #print(matches)\n",
    "       \n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            Id = known_face_ids[first_match_index]\n",
    "            face_ids.append(Id)\n",
    "\n",
    "    for (top, right, bottom, left), Id in zip(face_locations, face_ids):\n",
    "        \n",
    "        # Draw a box around the face\n",
    "        rec_image = cv2.rectangle(rgb_image, (left, top), (right, bottom), (0, 0, 255), int(3*scaledFont))\n",
    "        \n",
    "        # Draw a label with a name below the face\n",
    "#         cv2.rectangle(image_loaded, (left, bottom - (35*scaledFont)), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        imagen = cv2.putText(rec_image, photo_dic.get(str(Id), \"No hubo match\"), (left + 6, bottom + int(30*scaledFont)), font, scaledFont, (0, 0, 255), int(2*scaledFont))\n",
    "        output = \"{}img_{}.jpg\".format(outpath, Id)\n",
    "        cv2.imwrite(output, imagen)\n",
    "        \n",
    "    # Display the resulting image\n",
    "    #cv2.imshow('Video', imagen)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows() \n",
    "    print(face_ids)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/h_andrade/alarconyepezallansamuel_79578_1302992_Alarcón_Allan_grupal.jpg', 'data/h_andrade/alviaapraezjulioernesto_2808_1303099_Julio_Alvia_grupal.jpg', 'data/h_andrade/andradebravoboscoarmando_78451_1338359_Andrade_Bravo_grupal.jpg']\n",
      "[2808, 78451, 79578, 79578, 78451, 2808, 78451, 79578, 78451, 79578, 2808, 78451, 2808, 79578, 78451, 79578, 2808, 2808]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfaces,Ids = getImagesAndLabels(data_path)\\nrecognizer.train(faces, np.array(Ids))\\n#recognizer.save('trainner/trainner.yml')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data)\n",
    "print(known_face_ids)\n",
    "'''\n",
    "faces,Ids = getImagesAndLabels(data_path)\n",
    "recognizer.train(faces, np.array(Ids))\n",
    "#recognizer.save('trainner/trainner.yml')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# We point OpenCV\\'s CascadeClassifier function to where our \\n# classifier (XML file format) is stored\\nface_classifier = cv2.CascadeClassifier(\\'Haarcascades/haarcascade_frontalface_default.xml\\')\\n\\n# Load our image then convert it to grayscale\\n\"\"\"for Id,photo in test_data:\\n    image = cv2.imread(photo)\\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n    results = recognizer.predict(gray)\\n    \\n    print(Id == results[0])\"\"\"\\n\\nimage = cv2.imread(\\'data/h_andrade/alarconyepezallansamuel_79578_1302986_Alarcón_Allan_frontal.jpg\\')\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\nfaces = face_classifier.detectMultiScale(gray, 1.3, 5)\\n\\nif not faces:\\n    return image, []\\n\\nfor (x,y,w,h) in faces:\\n    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),2)\\n    roi = image[y:y+h, x:x+w]\\n    roi = cv2.resize(roi, (200, 200))\\n\\nresults = recognizer.predict(gray)    \\n\\ncv2.putText(image, photo_dic[str(results[0])], (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\\ncv2.imshow(\\'Face Recognition\\', image )\\n\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# We point OpenCV's CascadeClassifier function to where our \n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "\"\"\"for Id,photo in test_data:\n",
    "    image = cv2.imread(photo)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    results = recognizer.predict(gray)\n",
    "    \n",
    "    print(Id == results[0])\"\"\"\n",
    "\n",
    "image = cv2.imread('data/h_andrade/alarconyepezallansamuel_79578_1302986_Alarcón_Allan_frontal.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if not faces:\n",
    "    return image, []\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    roi = cv2.resize(roi, (200, 200))\n",
    "\n",
    "results = recognizer.predict(gray)    \n",
    "\n",
    "cv2.putText(image, photo_dic[str(results[0])], (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "cv2.imshow('Face Recognition', image )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
