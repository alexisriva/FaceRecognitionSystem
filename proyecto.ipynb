{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "test_path = 'test_data/'\n",
    "outpath = 'output/'\n",
    "\n",
    "# 'id':'name'\n",
    "photo_dic = {}\n",
    "\n",
    "# Array of known face encodings \n",
    "known_face_encodings = []\n",
    "known_face_ids=[]\n",
    "\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'79578': 'Alarc贸n Allan', '2808': 'Julio Alvia', '78451': 'Andrade Bravo'}\n",
      "Julio Alvia\n"
     ]
    }
   ],
   "source": [
    "for dirname, dirnames, filenames in os.walk(data_path):\n",
    "    for filename in filenames:\n",
    "        photo = os.path.join(dirname, filename)\n",
    "#         print(photo)\n",
    "        photo_data = photo.split(\"/\")[2].split(\".\")[0].split(\"_\")\n",
    "        photo_id = photo_data[1]\n",
    "        photo_name = \"{} {}\".format(photo_data[3], photo_data[4])\n",
    "        if photo_id not in photo_dic:\n",
    "            photo_dic[photo_id] = photo_name\n",
    "\n",
    "print(photo_dic)\n",
    "print(photo_dic[photo_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "# detector= cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_encoding - the model learns how to recognize it\n",
    "# face_id - to use it on the dictionary\n",
    "# photo_type - is grupal or not.\n",
    "\n",
    "def getImagesAndLabels(data_path): \n",
    "    total_test = 0\n",
    "    total_data = 0\n",
    "    encoded_at_first_try = 0\n",
    "    encoded_with_locations = 0\n",
    "    no_encoded = 0\n",
    "    \n",
    "    for dirname, dirnames, filenames in os.walk(data_path):\n",
    "        for filename in filenames:\n",
    "            photo_path = os.path.join(dirname, filename)\n",
    "            #print(photo_path)\n",
    "            face_id =int(photo_path.split(\"/\")[2].split(\".\")[0].split(\"_\")[1])\n",
    "            photo_type = photo_path.split(\"/\")[2].split(\".\")[0].split(\"_\")[-1]\n",
    "            \n",
    "            if photo_type.lower() == \"grupal\":\n",
    "                test_data.append(photo_path)\n",
    "                total_test += 1\n",
    "            else:\n",
    "                total_data += 1\n",
    "                image_loaded = face_recognition.load_image_file(photo_path)\n",
    "                face_encoding = face_recognition.face_encodings(image_loaded)\n",
    "\n",
    "                if face_encoding == []:\n",
    "                    img = cv2.imread(photo_path,0)\n",
    "                    height, width = img.shape[:2]\n",
    "                    known_face_locations=[(0, width, height, 0)]\n",
    "                    face_encoding = face_recognition.face_encodings(image_loaded,known_face_locations)\n",
    "\n",
    "                    if face_encoding == []:\n",
    "                        no_encoded += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        encoded_with_locations += 1\n",
    "                else:\n",
    "                    encoded_at_first_try += 1\n",
    "\n",
    "                face_encoding = face_encoding[0]\n",
    "                \n",
    "                known_face_encodings.append(face_encoding)\n",
    "                known_face_ids.append(face_id)\n",
    "            \n",
    "            print(str(no_encoded) +\" de \"+str(total_data)+\" sin encoding\")\n",
    "            print(str(total_test) + \" para test\")\n",
    "    return known_face_encodings, known_face_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagesToTest(test_path):\n",
    "\n",
    "    for dirname, dirnames, filenames in os.walk(test_path):\n",
    "        for filename in filenames:\n",
    "            photo_path = os.path.join(dirname, filename)\n",
    "            print(photo_path)\n",
    "            test_data.append(photo_path)\n",
    "                       \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleFont(photo):\n",
    "    img = cv2.imread(photo,0)\n",
    "    height, width = img.shape[:2]\n",
    "    min_value = min(height,width)\n",
    "    max_value = max(height,width)\n",
    "    if min_value < 900:\n",
    "        return min_value/900\n",
    "    elif max_value > 1300:\n",
    "        return max_value/1300\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 de 0 sin encoding\n",
      "1 para test\n",
      "0 de 1 sin encoding\n",
      "1 para test\n",
      "0 de 2 sin encoding\n",
      "1 para test\n",
      "0 de 3 sin encoding\n",
      "1 para test\n",
      "0 de 4 sin encoding\n",
      "1 para test\n",
      "0 de 5 sin encoding\n",
      "1 para test\n",
      "0 de 6 sin encoding\n",
      "1 para test\n",
      "0 de 6 sin encoding\n",
      "2 para test\n",
      "0 de 7 sin encoding\n",
      "2 para test\n",
      "0 de 8 sin encoding\n",
      "2 para test\n",
      "0 de 9 sin encoding\n",
      "2 para test\n",
      "0 de 10 sin encoding\n",
      "2 para test\n",
      "0 de 11 sin encoding\n",
      "2 para test\n",
      "0 de 11 sin encoding\n",
      "3 para test\n",
      "0 de 12 sin encoding\n",
      "3 para test\n",
      "0 de 13 sin encoding\n",
      "3 para test\n",
      "0 de 14 sin encoding\n",
      "3 para test\n",
      "0 de 15 sin encoding\n",
      "3 para test\n",
      "0 de 16 sin encoding\n",
      "3 para test\n",
      "0 de 17 sin encoding\n",
      "3 para test\n",
      "0 de 18 sin encoding\n",
      "3 para test\n"
     ]
    }
   ],
   "source": [
    "known_face_encodings, known_face_ids = getImagesAndLabels(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data/alarconyepezallansamuel_79578_1302992_Alarc贸n_Allan_grupal.jpg\n",
      "test_data/alviaapraezjulioernesto_2808_1303099_Julio_Alvia_grupal.jpg\n",
      "test_data/andradebravoboscoarmando_78451_1338359_Andrade_Bravo_grupal.jpg\n",
      "3\n",
      "[79578]\n",
      "3\n",
      "[2808]\n",
      "2\n",
      "[78451]\n",
      "['test_data/alarconyepezallansamuel_79578_1302992_Alarc贸n_Allan_grupal.jpg', 'test_data/alviaapraezjulioernesto_2808_1303099_Julio_Alvia_grupal.jpg', 'test_data/andradebravoboscoarmando_78451_1338359_Andrade_Bravo_grupal.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "test_data = getImagesToTest(test_path)\n",
    "for unknown_image in test_data:\n",
    "    #face_locations = face_recognition.face_locations(rgb_image)\n",
    "    image_loaded = face_recognition.load_image_file(unknown_image)\n",
    "    rgb_image = image_loaded[...,::-1]\n",
    "    face_locations = face_recognition.face_locations(rgb_image)\n",
    "    #face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "    #print(face_encodings)\n",
    "#     Id=\"\"\n",
    "    scaledFont = 1.0 * scaleFont(unknown_image)\n",
    "    face_ids=[]\n",
    "    print(len(face_encodings))\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        Id = -1\n",
    "    \n",
    "    #print(unknown_image)\n",
    "    #print(matches)\n",
    "       \n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            Id = known_face_ids[first_match_index]\n",
    "            face_ids.append(Id)\n",
    "\n",
    "    for (top, right, bottom, left), Id in zip(face_locations, face_ids):\n",
    "        \n",
    "        # Draw a box around the face\n",
    "        rec_image = cv2.rectangle(rgb_image, (left, top), (right, bottom), (0, 0, 255), int(3*scaledFont))\n",
    "        \n",
    "        # Draw a label with a name below the face\n",
    "#         cv2.rectangle(image_loaded, (left, bottom - (35*scaledFont)), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        imagen = cv2.putText(rec_image, photo_dic.get(str(Id), \"No hubo match\"), (left + 6, bottom + int(30*scaledFont)), font, scaledFont, (0, 0, 255), int(2*scaledFont))\n",
    "        output = \"{}img_{}.jpg\".format(outpath, Id)\n",
    "        cv2.imwrite(output, imagen)\n",
    "        \n",
    "    # Display the resulting image\n",
    "    #cv2.imshow('Video', imagen)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows() \n",
    "    print(face_ids)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/h_andrade/alarconyepezallansamuel_79578_1302992_Alarc贸n_Allan_grupal.jpg', 'data/h_andrade/alviaapraezjulioernesto_2808_1303099_Julio_Alvia_grupal.jpg', 'data/h_andrade/andradebravoboscoarmando_78451_1338359_Andrade_Bravo_grupal.jpg']\n",
      "[2808, 78451, 79578, 79578, 78451, 2808, 78451, 79578, 78451, 79578, 2808, 78451, 2808, 79578, 78451, 79578, 2808, 2808]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfaces,Ids = getImagesAndLabels(data_path)\\nrecognizer.train(faces, np.array(Ids))\\n#recognizer.save('trainner/trainner.yml')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data)\n",
    "print(known_face_ids)\n",
    "'''\n",
    "faces,Ids = getImagesAndLabels(data_path)\n",
    "recognizer.train(faces, np.array(Ids))\n",
    "#recognizer.save('trainner/trainner.yml')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# We point OpenCV\\'s CascadeClassifier function to where our \\n# classifier (XML file format) is stored\\nface_classifier = cv2.CascadeClassifier(\\'Haarcascades/haarcascade_frontalface_default.xml\\')\\n\\n# Load our image then convert it to grayscale\\n\"\"\"for Id,photo in test_data:\\n    image = cv2.imread(photo)\\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n    results = recognizer.predict(gray)\\n    \\n    print(Id == results[0])\"\"\"\\n\\nimage = cv2.imread(\\'data/h_andrade/alarconyepezallansamuel_79578_1302986_Alarc贸n_Allan_frontal.jpg\\')\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\nfaces = face_classifier.detectMultiScale(gray, 1.3, 5)\\n\\nif not faces:\\n    return image, []\\n\\nfor (x,y,w,h) in faces:\\n    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),2)\\n    roi = image[y:y+h, x:x+w]\\n    roi = cv2.resize(roi, (200, 200))\\n\\nresults = recognizer.predict(gray)    \\n\\ncv2.putText(image, photo_dic[str(results[0])], (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\\ncv2.imshow(\\'Face Recognition\\', image )\\n\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# We point OpenCV's CascadeClassifier function to where our \n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "\"\"\"for Id,photo in test_data:\n",
    "    image = cv2.imread(photo)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    results = recognizer.predict(gray)\n",
    "    \n",
    "    print(Id == results[0])\"\"\"\n",
    "\n",
    "image = cv2.imread('data/h_andrade/alarconyepezallansamuel_79578_1302986_Alarc贸n_Allan_frontal.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if not faces:\n",
    "    return image, []\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    roi = image[y:y+h, x:x+w]\n",
    "    roi = cv2.resize(roi, (200, 200))\n",
    "\n",
    "results = recognizer.predict(gray)    \n",
    "\n",
    "cv2.putText(image, photo_dic[str(results[0])], (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "cv2.imshow('Face Recognition', image )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
